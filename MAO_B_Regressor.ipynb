{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stawiskm/QSAR_LightGBM/blob/main/MAO_B_Regressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUViJbLfdARa"
      },
      "source": [
        "# **ACI Project: QSAR Regression models with RF and LightGBM on MAO-B inhibitors**\n",
        "---\n",
        "\n",
        "\n",
        "Marc Jermann   \\ Patrick Meier\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "While quantitative structure-activity relationship\n",
        "models are increasingly used nowadays, this study compares\n",
        "two different machine learning methods in just such QSAR\n",
        "models. The Light Gradient Boosting Machine method uses the\n",
        "well established decision tree approach and has been optimized\n",
        "for larger datasets. To test the applicability of this method, we\n",
        "compare it with a Random Forest model, the existing state-of-the-\n",
        "art method for such QSAR models, in three different applications.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In this Jupyter notebook, we will be building a real-life **data science project**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osrFkIR-xMu0"
      },
      "source": [
        "## **Introduction**\n",
        "Parkinson's disease is a progressive nervous system disorder that affects movement. Symptoms start gradually, sometimes starting with a barely noticeable tremor in just one hand. Tremors are common, but the disorder also commonly causes stiffness or slowing of movement.\n",
        "\n",
        "In the early stages of Parkinson's disease, your face may show little or no expression. Your arms may not swing when you walk. Your speech may become soft or slurred. Parkinson's disease symptoms worsen as your condition progresses over time.\n",
        "\n",
        "Although Parkinson's disease can't be cured, medications might significantly improve your symptoms. Occasionally, your doctor may suggest surgery to regulate certain regions of your brain and improve your symptoms.\n",
        "(https://www.mayoclinic.org/diseases-conditions/parkinsons-disease/symptoms-causes/syc-20376055)\n",
        "\n",
        "### *Monoamine Oxidase B*\n",
        "Monoamine Oxidase Type B (MAO-B) is an enzyme in our body that breaks down several chemicals in the brain, including dopamine. By giving a medication that blocks the effect of MAO-B, an MAO-B inhibitor), more dopamine is available to be used by the brain. This can modestly improve many motor symptoms of PD. (https://www.parkinson.org/Understanding-Parkinsons/Treatment/Prescription-Medications/MAO-B-Inhibitors)\n",
        "\n",
        "### *Literature regarding MAO B*\n",
        "\n",
        "*  Comparative effectiveness of dopamine agonists and monoamine oxidase type-B inhibitors for Parkinson's disease: a multiple treatment comparison meta-analysis [(Eur J Clin Pharmacol)]()https://doi.org/10.1007/s00228-020-02961-6)\n",
        "\n",
        "*   Monoamine Oxidase B Inhibitors in Parkinson's Disease [(CNS Neurol Disord Drug Targets)](https://doi.org/10.2174/1871527316666170124165222)\n",
        "\n",
        "*  Long-term effectiveness of dopamine agonists and monoamine oxidase B inhibitors compared with levodopa as initial treatment for Parkinson's disease (PD MED): a large, open-label, pragmatic randomised trial [(Lancet)](https://doi.org/10.1016/s0140-6736(14)60683-8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGSX4a0X8CrV"
      },
      "source": [
        "### *Monoamine oxidase type-B*\n",
        "\n",
        "![picture](https://institute.progress.im/sites/default/files/styles/content_full/public/lundbeck_lic_illustrationer_02_09_depression_-_moa_of_mao-bi.png?itok=xCmdEPMO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs9STyzE96z8"
      },
      "source": [
        "## **Investigating target protein**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFOtDbpWSsBR",
        "outputId": "583e4e12-0106-410b-b1bc-c95b7397cd5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chembl_webresource_client\n",
            "  Downloading chembl_webresource_client-0.10.8-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 30 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 40 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 51 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from chembl_webresource_client) (1.24.3)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from chembl_webresource_client) (1.9)\n",
            "Collecting requests-cache~=0.7.0\n",
            "  Downloading requests_cache-0.7.5-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from chembl_webresource_client) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->chembl_webresource_client) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->chembl_webresource_client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->chembl_webresource_client) (2.10)\n",
            "Collecting itsdangerous>=2.0.1\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Collecting pyyaml>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.2 MB/s \n",
            "\u001b[?25hCollecting url-normalize<2.0,>=1.4\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: attrs<22.0,>=21.2 in /usr/local/lib/python3.7/dist-packages (from requests-cache~=0.7.0->chembl_webresource_client) (21.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from url-normalize<2.0,>=1.4->requests-cache~=0.7.0->chembl_webresource_client) (1.15.0)\n",
            "Installing collected packages: url-normalize, pyyaml, itsdangerous, requests-cache, chembl-webresource-client\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: itsdangerous\n",
            "    Found existing installation: itsdangerous 1.1.0\n",
            "    Uninstalling itsdangerous-1.1.0:\n",
            "      Successfully uninstalled itsdangerous-1.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires itsdangerous<2.0,>=0.24, but you have itsdangerous 2.1.2 which is incompatible.\u001b[0m\n",
            "Successfully installed chembl-webresource-client-0.10.8 itsdangerous-2.1.2 pyyaml-6.0 requests-cache-0.7.5 url-normalize-1.4.3\n"
          ]
        }
      ],
      "source": [
        "# Install ChEMBL webresource client\n",
        "! pip install chembl_webresource_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bzLxaTJuS74x"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd \n",
        "from chembl_webresource_client.new_client import new_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNk_x8UOS-Ts"
      },
      "outputs": [],
      "source": [
        "# Target search for Monoamine oxidase B (MAO-B), Parkinson (~5 minutes)\n",
        "target = new_client.target\n",
        "target_query = target.search('Monoamine oxidase B')\n",
        "targets = pd.DataFrame.from_dict(target_query)\n",
        "targets.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypvYTWnxS-Xj"
      },
      "outputs": [],
      "source": [
        "# Regex filter to search for the term Monoamine oxidase followed by a B\n",
        "targets.loc[(targets[\"organism\"] == \"Homo sapiens\") & (targets[\"pref_name\"].str.contains('Monoamine oxidase.*B', regex=True))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul6FyoE-S__f"
      },
      "outputs": [],
      "source": [
        "# Selection of CHEMBL2039 as target, since it is referenced as Homo Sapiens and has the correct pref_name\n",
        "selected_target = targets.target_chembl_id[4]\n",
        "selected_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y5aiTEOTM43"
      },
      "outputs": [],
      "source": [
        "# Load activity data of the target filtered by half maximal inhibitory concentration (IC50) (~8min)\n",
        "activity = new_client.activity\n",
        "res = activity.filter(target_chembl_id=selected_target).filter(standard_type=\"IC50\")\n",
        "df = pd.DataFrame.from_dict(res)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRiL8PdSSmWy"
      },
      "outputs": [],
      "source": [
        "# Number of molecules (5067 Entries on April 25th 2022)\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReYnBZ5YTPKP"
      },
      "outputs": [],
      "source": [
        "df.to_csv('MAOB_bioactivity.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D8tnxRa6LqG"
      },
      "source": [
        "#### (possible shortcut)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxuRN2Sabaef"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://github.com/stawiskm/QSAR_LightGBM/raw/main/data/MAOB_bioactivity.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlxF4djNTXq_"
      },
      "outputs": [],
      "source": [
        "# Remove entries where standard_value is NAN\n",
        "df2 = df[df.standard_value.notna()]\n",
        "df2 = df2[df.canonical_smiles.notna()]\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gAvrVsXTggG"
      },
      "outputs": [],
      "source": [
        "# Subset of the dataframe only using the molecule_chembl_id, canonical_smiles and standard_value\n",
        "selection = ['molecule_chembl_id','canonical_smiles','standard_value']\n",
        "df3 = df2[selection]\n",
        "df3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjWLnIa1ksAZ"
      },
      "outputs": [],
      "source": [
        "# df.canonical_smiles.tolist()\n",
        "test_smile = 'C=C(CNN)c1ccccc1.Cl'\n",
        "test_smile\n",
        "test_smile.split('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DtDOj8TfnsD"
      },
      "outputs": [],
      "source": [
        "def cleanSMILES(row):\n",
        "    cpd = str(row.canonical_smiles).split('.')\n",
        "    cpd_longest = max(cpd, key = len)\n",
        "    return cpd_longest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HICvjpTHUt9K"
      },
      "outputs": [],
      "source": [
        "df3[\"smiles\"] = df3.apply(cleanSMILES ,axis=1)\n",
        "df3 = df3.drop(\"canonical_smiles\",axis=1)\n",
        "df3 = df3.rename({\"smiles\":\"canonical_smiles\"},axis=1)\n",
        "df3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qlj-j5ATfOG"
      },
      "outputs": [],
      "source": [
        "# Drop duplicate smiles\n",
        "df3 = df3.drop_duplicates(['canonical_smiles'])\n",
        "df3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhB1q5Z2TccO"
      },
      "outputs": [],
      "source": [
        "# Number of unique molecules (4216 Entries on April 25th 2022)\n",
        "len(df3.canonical_smiles.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3ZKJtUDT1hl"
      },
      "outputs": [],
      "source": [
        "df3.to_csv('MAOB_bioactivity_data_preprocessed.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npBPE4QRdWdB"
      },
      "outputs": [],
      "source": [
        "def norm_value(input):\n",
        "    norm = []\n",
        "\n",
        "    for i in input['standard_value']:\n",
        "        #  Values greater than 100,000,000 will be fixed at 100,000,000 otherwise the negative logarithmic value will become negative.\n",
        "        if i > 100000000:\n",
        "          i = 100000000\n",
        "        norm.append(i)\n",
        "\n",
        "    input['standard_value_norm'] = norm\n",
        "    x = input.drop('standard_value', 1)\n",
        "        \n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szVCU5SPO866"
      },
      "outputs": [],
      "source": [
        "df3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_EoYH6DdYyv"
      },
      "outputs": [],
      "source": [
        "df_norm = norm_value(df3)\n",
        "df_norm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bw_AGmJY8AR"
      },
      "source": [
        "### Convert IC50 to pIC50\n",
        "\n",
        "> To allow IC50 data to be more uniformly distributed, we will convert IC50 to the negative logarithmic scale which is essentially -log10(IC50).\n",
        "This custom function pIC50() will accept a DataFrame as input and will:\n",
        "Take the IC50 values from the standard_value column and converts it from nM to M by multiplying the value by 10 −9 \n",
        "Take the molar value and apply -log10\n",
        "Delete the standard_value column and create a new pIC50 column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgVtSepTNGti"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# https://github.com/chaninlab/estrogen-receptor-alpha-qsar/blob/master/02_ER_alpha_RO5.ipynb\n",
        "\n",
        "def pIC50(input):\n",
        "    pIC50 = []\n",
        "\n",
        "    for i in input['standard_value_norm']:\n",
        "        molar = i*(10**-9) # Converts nM to M\n",
        "        pIC50.append(-np.log10(molar))\n",
        "\n",
        "    input['pIC50'] = pIC50\n",
        "    x = input.drop('standard_value_norm', 1)\n",
        "        \n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-jzbGiwZPjn"
      },
      "outputs": [],
      "source": [
        "df_final = pIC50(df_norm)\n",
        "df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP161hhUZTq-"
      },
      "outputs": [],
      "source": [
        "df_final.to_csv('MAOB_bioactivity_final.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhNGjHRKJJLc"
      },
      "source": [
        "## Feature encoding with PaDEL-Descriptor\n",
        "\n",
        "A software that calculates molecular descriptors and fingerprints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x0AMOXVfTev"
      },
      "outputs": [],
      "source": [
        "! wget https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip\n",
        "! wget https://github.com/dataprofessor/bioinformatics/raw/master/padel.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "467BCee5drcm"
      },
      "source": [
        "## Data handling\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L83utxa8e2vx"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('MAOB_bioactivity_final.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf-i85gtaaib"
      },
      "outputs": [],
      "source": [
        "selection = ['canonical_smiles','molecule_chembl_id']\n",
        "df_sel = df[selection]\n",
        "df_sel.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpDOfxKHVIDz"
      },
      "outputs": [],
      "source": [
        "df_sel.to_csv('molecule.smi', sep='\\t', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFmXf8TQHq3O"
      },
      "outputs": [],
      "source": [
        " ! cat molecule.smi | head -5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pGncZoAfsFJ"
      },
      "outputs": [],
      "source": [
        "! unzip padel.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLn47bVnTcmf"
      },
      "outputs": [],
      "source": [
        "# Running the padel descriptor tool on the created molecule.smi data (~12min)\n",
        "! bash padel.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0w2-yH-U84a"
      },
      "outputs": [],
      "source": [
        "# Read in the file created from the PaDEL descriptor tool\n",
        "df3_X = pd.read_csv('descriptors_output.csv')\n",
        "df3_X.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5QouQB4gX3m"
      },
      "outputs": [],
      "source": [
        "# Create a target dataset containing the pIC50 value and the chembl id\n",
        "df3_Y = df[['pIC50','molecule_chembl_id']]\n",
        "df3_Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1T97Wj0gbl7"
      },
      "outputs": [],
      "source": [
        "# Merge the datasets together based on the unique ChEMBL id\n",
        "df = pd.merge(df3_X,df3_Y, left_on=['Name'], right_on=['molecule_chembl_id'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLkpbfRCQm9y"
      },
      "outputs": [],
      "source": [
        "# Remove the ChEMBL id to create a dataframe only with the Pubchem features\n",
        "df = df.drop(columns=['Name', 'molecule_chembl_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5TbFKJDgfaK"
      },
      "outputs": [],
      "source": [
        "df.to_csv('MAOB_bioactivity_pubchem.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXcQihqZ6PiK"
      },
      "source": [
        "#### (possible shortcut)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q1ix_c3g5Ri"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://github.com/stawiskm/QSAR_LightGBM/raw/main/data/MAOB_bioactivity_pubchem.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJcRRP7ukuTk"
      },
      "outputs": [],
      "source": [
        "# Remove all entries where pIC50 is NaN\n",
        "df = df[df['pIC50'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wglqLyk2jyRr"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yTa6Dq5eOqT"
      },
      "outputs": [],
      "source": [
        "# Create a feature dataset X without the pIC50 target value\n",
        "X = df.drop('pIC50',axis=1)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWa_0dsIfddv"
      },
      "outputs": [],
      "source": [
        "# Create a target dataset containing only the pIC50 target \n",
        "y = df['pIC50']\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTFg9lQxYnKM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o82mWYZSYrfX"
      },
      "outputs": [],
      "source": [
        "# Split the data into 80% training and 20% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPDRntKfiQVQ"
      },
      "outputs": [],
      "source": [
        "# Check if the shape of the datasets is still correct\n",
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBgg7q-gXhiL"
      },
      "outputs": [],
      "source": [
        "X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYsE-tIAhSw3"
      },
      "source": [
        "## **Building a Regression Model using Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AmW3HdRbCiD"
      },
      "source": [
        "### **Random Forest Internal validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sGzBCBH0NAo"
      },
      "source": [
        "Then the Regression models are built, starting with the well-established Random Forest. \n",
        "First, the scoring is defined, which is used for all subsequent cross validations. Then, a stratified 5 fold cross-validation of a Random Forest model with optimized parameters is performed and the results of this internal validation are stored in a table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMV6JWwINQY5"
      },
      "outputs": [],
      "source": [
        "# The scorers can be either one of the predefined metric strings or a scorer\n",
        "# callable, like the one returned by make_scorer\n",
        "\n",
        "from sklearn.metrics import max_error,mean_absolute_error,r2_score,mean_squared_error,make_scorer\n",
        "\n",
        "scoring = {\"MaxError\": make_scorer(max_error),\n",
        "           \"MAE\": make_scorer(mean_absolute_error),\n",
        "           \"MSE\": make_scorer(mean_squared_error),\n",
        "           \"R2\": make_scorer(r2_score)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHM3DCD5wuNe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "parameters = {'max_depth': [5,10],\n",
        "              'min_samples_leaf': [3,5],\n",
        "              'min_samples_split': [5],\n",
        "              'n_estimators': [1000]\n",
        "              }\n",
        "\n",
        "cv = KFold(n_splits=5,shuffle=True,random_state=42)\n",
        "\n",
        "clf = GridSearchCV(rf, parameters,cv=cv,verbose=2,n_jobs=-1,scoring=scoring,refit=\"R2\",return_train_score=True)\n",
        "\n",
        "startTime = time.time()\n",
        "\n",
        "#Model search\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "executionTime = (time.time() - startTime)\n",
        "print('Execution time in seconds: ' + str(executionTime))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOI66ropqRfY"
      },
      "outputs": [],
      "source": [
        "parameterlist = []\n",
        "for parameter in list(parameters.keys()):\n",
        "  feature = \"param_\"+parameter\n",
        "  parameterlist.append(feature)\n",
        "print(parameterlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nXGwxc1bbF7"
      },
      "outputs": [],
      "source": [
        "def defineSet(row):\n",
        "    return str(row.variable).split(\"_\")[1]\n",
        "def defineMetric(row):\n",
        "    return str(row.variable).split(\"_\")[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xucBx65E4KL"
      },
      "outputs": [],
      "source": [
        "def defineRFModelName(df):\n",
        "    name = \"RF_model_\"\n",
        "    count = 1\n",
        "    modelNames = []\n",
        "    oldParam=[None]\n",
        "    for param in df.params:\n",
        "        if param not in oldParam:\n",
        "            count = count + 1\n",
        "            oldParam.append(param)\n",
        "        modelNames.append(name+str(oldParam.index(param)))\n",
        "    return modelNames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfoI_QOESW0U"
      },
      "outputs": [],
      "source": [
        "dfGridsearch = pd.DataFrame(clf.cv_results_)\n",
        "droplist = ['mean_fit_time', 'std_fit_time',\n",
        "            'mean_score_time', 'std_score_time',\n",
        "            'mean_test_MaxError', 'std_test_MaxError','rank_test_MaxError', 'mean_train_MaxError', 'std_train_MaxError',\n",
        "            'mean_test_MAE', 'std_test_MAE','rank_test_MAE','mean_train_MAE', 'std_train_MAE', \n",
        "            'mean_test_MSE', 'std_test_MSE', 'rank_test_MSE', 'mean_train_MSE', 'std_train_MSE', 'split0_test_R2',\n",
        "            'mean_test_R2', 'std_test_R2', 'rank_test_R2', 'mean_train_R2', 'std_train_R2'\n",
        "            ]+parameterlist\n",
        "dfScoreResults = dfGridsearch.drop(droplist,axis=1)\n",
        "dfScoreResults = pd.melt(dfScoreResults, id_vars=['params'])\n",
        "dfScoreResults[\"set\"] = dfScoreResults.apply(defineSet, axis=1)\n",
        "dfScoreResults[\"metric\"] = dfScoreResults.apply(defineMetric, axis=1)\n",
        "dfScoreResults = dfScoreResults.drop([\"variable\"],axis=1)\n",
        "dfScoreResults[\"params\"]=dfScoreResults[\"params\"].astype(str)\n",
        "dfScoreResults[\"method\"]= \"Random Forest\"\n",
        "dfScoreResults[\"model\"] = defineRFModelName(dfScoreResults)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orA4nfr6JVQc"
      },
      "outputs": [],
      "source": [
        "searchparam = str(clf.best_params_)\n",
        "dfScoreResults[dfScoreResults[\"params\"]==searchparam].head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMCYPmpoXqbU"
      },
      "outputs": [],
      "source": [
        "# for comparison\n",
        "dfScoreRFresult = dfScoreResults[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4ng6XyOb7jc"
      },
      "source": [
        "### **Random Forest External validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIstCIM5Pyqo"
      },
      "source": [
        "This optimized Random Forest model is now trained again with the entire training set and the time needed to train the model is recorded. Finally, the test set is predicted for external validation and the scores of the various metrics are recorded in a table. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1C8IN1SuwZ_"
      },
      "outputs": [],
      "source": [
        "ModelResultsTable = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nvOASayb6vr"
      },
      "outputs": [],
      "source": [
        "print(clf.best_params_)\n",
        "model =  RandomForestRegressor(max_depth=clf.best_params_[\"max_depth\"],\n",
        "                               min_samples_leaf=clf.best_params_[\"min_samples_leaf\"],\n",
        "                               min_samples_split=clf.best_params_[\"min_samples_split\"],\n",
        "                               n_estimators=clf.best_params_[\"n_estimators\"],\n",
        "                               random_state=42)\n",
        "\n",
        "\n",
        "startTime = time.time()\n",
        "\n",
        "#Model training\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "executionTime = (time.time() - startTime)\n",
        "print('Execution time in seconds: ' + str(executionTime))\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "MaxError = max_error(y_test,y_pred)\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "MSE = mean_squared_error(y_test,y_pred)\n",
        "R2 = r2_score(y_test,y_pred)\n",
        "output = pd.DataFrame({\"Model\":\"RF_model_3\",\"R2\":R2,\"MAE\":MAE,\"MSE\":MSE,\"MaxError\":MaxError,\"Params\":[clf.best_params_],\"ExecutionTime\":executionTime})\n",
        "ModelResultsTable = pd.concat([output, ModelResultsTable], ignore_index=True)\n",
        "ModelResultsTable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvx5SCz5VT89"
      },
      "source": [
        "## **Building a Regression Model using LGBMClassifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qsuf__WVT8-"
      },
      "source": [
        "### **LightGBM Internal validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF6ytgJQYquD"
      },
      "source": [
        "The next step is to create various LightGBM models using a gridsearch, combining previously defined parameters in all possible ways to create 48 different models. These models undergo the same stratified 5 fold cross validations with the same metrics as Random Forest models before. These results are also stored in a table for internal validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtLNbe2oVT8-"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "lgbm = LGBMRegressor(random_state=42)\n",
        "\n",
        "parameters = {\"boosting_type\":[\"gbdt\",\"dart\"],\n",
        "              \"learning_rate\":[0.063,0.126],\n",
        "              \"n_estimators\" :[6,24,96],\n",
        "              \"num_leaves\" : [32,64],\n",
        "              \"subsample_for_bin\":[60000],\n",
        "              'max_depth': [21,42]\n",
        "              }\n",
        "cv = KFold(n_splits=5, shuffle=True,random_state=42)\n",
        "\n",
        "clf = GridSearchCV(lgbm, parameters,cv=cv,verbose=2,n_jobs=-1,scoring=scoring,refit=\"R2\",return_train_score=True)\n",
        "\n",
        "startTime = time.time()\n",
        "\n",
        "#Model search\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "executionTime = (time.time() - startTime)\n",
        "print('Execution time in seconds: ' + str(executionTime))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp0gYbEFVT8-"
      },
      "outputs": [],
      "source": [
        "parameterlist = []\n",
        "for parameter in list(parameters.keys()):\n",
        "  feature = \"param_\"+parameter\n",
        "  parameterlist.append(feature)\n",
        "print(parameterlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSl_TnY9fX9I"
      },
      "outputs": [],
      "source": [
        "def defineModelName(df):\n",
        "    name = \"LGBM_model_\"\n",
        "    count = 1\n",
        "    modelNames = []\n",
        "    oldParam=[None]\n",
        "    for param in df.params:\n",
        "        if param not in oldParam:\n",
        "            count = count + 1\n",
        "            oldParam.append(param)\n",
        "        modelNames.append(name+str(oldParam.index(param)))\n",
        "    return modelNames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJxmD7akVT8_"
      },
      "outputs": [],
      "source": [
        "dfGridsearch = pd.DataFrame(clf.cv_results_)\n",
        "droplist = ['mean_fit_time', 'std_fit_time',\n",
        "            'mean_score_time', 'std_score_time',\n",
        "            'mean_test_MaxError', 'std_test_MaxError','rank_test_MaxError', 'mean_train_MaxError', 'std_train_MaxError',\n",
        "            'mean_test_MAE', 'std_test_MAE','rank_test_MAE','mean_train_MAE', 'std_train_MAE', \n",
        "            'mean_test_MSE', 'std_test_MSE', 'rank_test_MSE', 'mean_train_MSE', 'std_train_MSE', 'split0_test_R2',\n",
        "            'mean_test_R2', 'std_test_R2', 'rank_test_R2', 'mean_train_R2', 'std_train_R2'\n",
        "            ]+parameterlist\n",
        "dfScoreResults = dfGridsearch.drop(droplist,axis=1)\n",
        "dfScoreResults = pd.melt(dfScoreResults, id_vars=['params'])\n",
        "dfScoreResults[\"set\"] = dfScoreResults.apply(defineSet, axis=1)\n",
        "dfScoreResults[\"metric\"] = dfScoreResults.apply(defineMetric, axis=1)\n",
        "dfScoreResults = dfScoreResults.drop([\"variable\"],axis=1)\n",
        "dfScoreResults[\"params\"]=dfScoreResults[\"params\"].astype(str)\n",
        "dfScoreResults[\"method\"]= \"LightGBM\"\n",
        "dfScoreResults[\"model\"] = defineModelName(dfScoreResults)\n",
        "dfScoreResults = pd.concat([dfScoreResults,dfScoreRFresult],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "644Hwz2LVjzC"
      },
      "outputs": [],
      "source": [
        "modelsParamsDict = dfScoreResults[[\"model\",\"params\"]].set_index('model').drop_duplicates().to_dict('index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEbaLHb8UL_B"
      },
      "outputs": [],
      "source": [
        "dfScoreResults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQh8Ve1tVT9A"
      },
      "source": [
        "### **LightGBM External validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5jaGEN0ffdP"
      },
      "source": [
        "As with the Random Forest Model, the best four LightGBM models, the models that achieved the highest average accuracy values during the internal validation, are now trained again for the external validation and evaluated with the test set. \n",
        "\n",
        "LGBM_model_18\n",
        "\n",
        "LGBM_model_24 \n",
        "\n",
        "LGBM_model_23\n",
        "\n",
        "LGBM_model_17\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws7pCIrjkPvU"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "clfmodel = ast.literal_eval(modelsParamsDict[\"LGBM_model_18\"][\"params\"])\n",
        "print(clfmodel)\n",
        "model =  LGBMRegressor(boosting_type=clfmodel[\"boosting_type\"],\n",
        "                        learning_rate=clfmodel['learning_rate'],\n",
        "                        n_estimators=clfmodel['n_estimators'],\n",
        "                        num_leaves=clfmodel['num_leaves'],\n",
        "                        subsample_for_bin=clfmodel[\"subsample_for_bin\"],\n",
        "                        max_depth=clfmodel[\"max_depth\"],\n",
        "                        random_state=42)\n",
        "startTime = time.time()\n",
        "\n",
        "#Model training\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "executionTime = (time.time() - startTime)\n",
        "print('Execution time in seconds: ' + str(executionTime))\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "MaxError = max_error(y_test,y_pred)\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "MSE = mean_squared_error(y_test,y_pred)\n",
        "R2 = r2_score(y_test,y_pred)\n",
        "\n",
        "output = pd.DataFrame({\"Model\":\"LGBM_model_18\",\"R2\":R2,\"MAE\":MAE,\"MSE\":MSE,\"MaxError\":MaxError,\"Params\":[clf.best_params_],\"ExecutionTime\":executionTime})\n",
        "ModelResultsTable = pd.concat([output, ModelResultsTable], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9evOZ9YykL7G"
      },
      "outputs": [],
      "source": [
        "clfmodel = ast.literal_eval(modelsParamsDict[\"LGBM_model_24\"][\"params\"])\n",
        "print(clfmodel)\n",
        "model =  LGBMRegressor(boosting_type=clfmodel[\"boosting_type\"],\n",
        "                        learning_rate=clfmodel['learning_rate'],\n",
        "                        n_estimators=clfmodel['n_estimators'],\n",
        "                        num_leaves=clfmodel['num_leaves'],\n",
        "                        subsample_for_bin=clfmodel[\"subsample_for_bin\"],\n",
        "                        max_depth=clfmodel[\"max_depth\"],\n",
        "                        random_state=42)\n",
        "startTime = time.time()\n",
        "\n",
        "#Model training\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "executionTime = (time.time() - startTime)\n",
        "print('Execution time in seconds: ' + str(executionTime))\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "MaxError = max_error(y_test,y_pred)\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "MSE = mean_squared_error(y_test,y_pred)\n",
        "R2 = r2_score(y_test,y_pred)\n",
        "\n",
        "output = pd.DataFrame({\"Model\":\"LGBM_model_24\",\"R2\":R2,\"MAE\":MAE,\"MSE\":MSE,\"MaxError\":MaxError,\"Params\":[clf.best_params_],\"ExecutionTime\":executionTime})\n",
        "ModelResultsTable = pd.concat([output, ModelResultsTable], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNzaXob-8ApM"
      },
      "outputs": [],
      "source": [
        "clfmodel = ast.literal_eval(modelsParamsDict[\"LGBM_model_23\"][\"params\"])\n",
        "print(clfmodel)\n",
        "model =  LGBMRegressor(boosting_type=clfmodel[\"boosting_type\"],\n",
        "                        learning_rate=clfmodel['learning_rate'],\n",
        "                        n_estimators=clfmodel['n_estimators'],\n",
        "                        num_leaves=clfmodel['num_leaves'],\n",
        "                        subsample_for_bin=clfmodel[\"subsample_for_bin\"],\n",
        "                        max_depth=clfmodel[\"max_depth\"],\n",
        "                        random_state=42)\n",
        "startTime = time.time()\n",
        "\n",
        "#Model training\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "executionTime = (time.time() - startTime)\n",
        "print('Execution time in seconds: ' + str(executionTime))\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "MaxError = max_error(y_test,y_pred)\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "MSE = mean_squared_error(y_test,y_pred)\n",
        "R2 = r2_score(y_test,y_pred)\n",
        "\n",
        "output = pd.DataFrame({\"Model\":\"LGBM_model_23\",\"R2\":R2,\"MAE\":MAE,\"MSE\":MSE,\"MaxError\":MaxError,\"Params\":[clf.best_params_],\"ExecutionTime\":executionTime})\n",
        "ModelResultsTable = pd.concat([output, ModelResultsTable], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDZK1gopVT9A"
      },
      "outputs": [],
      "source": [
        "clfmodel = ast.literal_eval(modelsParamsDict[\"LGBM_model_17\"][\"params\"])\n",
        "print(clfmodel)\n",
        "model =  LGBMRegressor(boosting_type=clfmodel[\"boosting_type\"],\n",
        "                        learning_rate=clfmodel['learning_rate'],\n",
        "                        n_estimators=clfmodel['n_estimators'],\n",
        "                        num_leaves=clfmodel['num_leaves'],\n",
        "                        subsample_for_bin=clfmodel[\"subsample_for_bin\"],\n",
        "                        max_depth=clfmodel[\"max_depth\"],\n",
        "                        random_state=42)\n",
        "\n",
        "startTime = time.time()\n",
        "\n",
        "#Model training\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "executionTime = (time.time() - startTime)\n",
        "print('Execution time in seconds: ' + str(executionTime))\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "MaxError = max_error(y_test,y_pred)\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "MSE = mean_squared_error(y_test,y_pred)\n",
        "R2 = r2_score(y_test,y_pred)\n",
        "\n",
        "output = pd.DataFrame({\"Model\":\"LGBM_model_17\",\"R2\":R2,\"MAE\":MAE,\"MSE\":MSE,\"MaxError\":MaxError,\"Params\":[clf.best_params_],\"ExecutionTime\":executionTime})\n",
        "ModelResultsTable = pd.concat([output, ModelResultsTable], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO0kejrZaHZx"
      },
      "source": [
        "## **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUkLFFQJ2YhW"
      },
      "source": [
        "### **Random Forest Internal validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gscwz_MitriK"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IgArT3tHVst"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.set(rc = {'figure.figsize':(4,8)})\n",
        "ax = sns.boxplot(x=\"model\", y=\"value\", hue=\"set\", data=dfScoreResults[(dfScoreResults[\"metric\"]==\"R2\")&(dfScoreResults[\"method\"]==\"Random Forest\")])\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
        "plt.plot()\n",
        "plt.savefig('result_RF_TrainVsTest.png', dpi=300, format='png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nTvT8HiUAAh"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.set(rc = {'figure.figsize':(4,8)})\n",
        "ax = sns.boxplot(x=\"set\", y=\"value\", hue=\"metric\", data=dfScoreResults[dfScoreResults[\"method\"]==\"Random Forest\"])\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
        "plt.plot()\n",
        "plt.savefig('result_RF_TrainVsTest.png', dpi=300, format='png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dSwLmMhIwoF"
      },
      "source": [
        "### **LightGBM Internal validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpYq0N8ymIaZ"
      },
      "outputs": [],
      "source": [
        "removeModels = dfScoreResults.loc[dfScoreResults[\"value\"]<0][\"model\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCGQNyi1EJV3"
      },
      "outputs": [],
      "source": [
        "removeModels = list(removeModels)\n",
        "removeModels.append(\"RF_model_4\")\n",
        "removeModels.append(\"RF_model_1\")\n",
        "removeModels.append(\"RF_model_2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNU2boXUohNF"
      },
      "outputs": [],
      "source": [
        "removeModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1wAwX3ulzBg"
      },
      "outputs": [],
      "source": [
        "dfScoreResults= dfScoreResults.loc[~(dfScoreResults[\"model\"].isin(removeModels))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_Fa7MaiZsvn"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Mean of R2:\\n\",dfScoreResults[(dfScoreResults[\"metric\"]==\"R2\")&(dfScoreResults[\"set\"]==\"test\")].groupby([\"method\"]).mean())\n",
        "print(\"\\n Std of R2:\\n\",dfScoreResults[(dfScoreResults[\"metric\"]==\"R2\")&(dfScoreResults[\"set\"]==\"test\")].groupby([\"method\"]).std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbHUo3bRJkia"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Mean of MSE:\\n\",dfScoreResults[(dfScoreResults[\"metric\"]==\"MSE\")&(dfScoreResults[\"set\"]==\"test\")].groupby([\"method\"]).mean())\n",
        "print(\"\\n Std of MSE:\\n\",dfScoreResults[(dfScoreResults[\"metric\"]==\"MSE\")&(dfScoreResults[\"set\"]==\"test\")].groupby([\"method\"]).std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4e6Aj6rnJz66"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Mean of MAE:\\n\",dfScoreResults[(dfScoreResults[\"metric\"]==\"MAE\")&(dfScoreResults[\"set\"]==\"test\")].groupby([\"method\"]).mean())\n",
        "print(\"\\n Std of MAE:\\n\",dfScoreResults[(dfScoreResults[\"metric\"]==\"MAE\")&(dfScoreResults[\"set\"]==\"test\")].groupby([\"method\"]).std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jjvfp0lgiYKH"
      },
      "outputs": [],
      "source": [
        "dfScoreResultsByParams = dfScoreResults[(dfScoreResults[\"metric\"]==\"R2\")&(dfScoreResults[\"set\"]==\"test\")].groupby([\"model\"]).mean()\n",
        "dfScoreResultsByParams = dfScoreResultsByParams.sort_values('value', ascending = False)\n",
        "dfScoreResultsByParamsSubset = dfScoreResultsByParams[dfScoreResultsByParams.value > 0.53]\n",
        "print(\"\\nMean R2 of best models:\\n\",dfScoreResultsByParamsSubset)\n",
        "bestModels = list(dfScoreResultsByParamsSubset.index)\n",
        "print(\"\\n\\nmodels showing best R2 in internal validation: \\n\",bestModels)\n",
        "dfScoreResultsByParamsSTD = dfScoreResults[(dfScoreResults[\"metric\"]==\"R2\")&(dfScoreResults[\"set\"]==\"test\")].groupby([\"model\"]).std()\n",
        "dfScoreResultsByParamsSTDSubset = dfScoreResultsByParamsSTD[dfScoreResultsByParams.value > 0.53]\n",
        "print(\"\\n Std R2 of best models:\\n\",dfScoreResultsByParamsSTDSubset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N0Wj7ji0VT8_"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.set(rc = {'figure.figsize':(15,8)})\n",
        "ax = sns.boxplot(x=\"model\", y=\"value\",hue=\"method\", data=dfScoreResults[(dfScoreResults[\"metric\"]==\"R2\")&(dfScoreResults[\"set\"]==\"test\")],palette=\"Greys\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
        "ax.set(title='R-squares of the models created during gridsearch')\n",
        "ax.set_ylabel(\"R-squared\")\n",
        "ax.set_ylim(0.1,0.7)\n",
        "plt.plot()\n",
        "plt.savefig('result_R2_RF-Vs-LGBM.png', dpi=300, format='png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_2P1ciG1CvPP"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.set(rc = {'figure.figsize':(4,8)})\n",
        "ax = sns.boxplot(x=\"model\", y=\"value\", hue=\"metric\", data=dfScoreResults[(dfScoreResults[\"model\"].isin(bestModels))&(dfScoreResults[\"set\"]==\"test\")])\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
        "ax.set(title='Internal validation best models')\n",
        "plt.plot()\n",
        "plt.savefig('result_R2_RF-Vs-BestLGBM.png', dpi=300, format='png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PqWvLX_eU5rI"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.set(rc = {'figure.figsize':(8,4)})\n",
        "ax = sns.boxplot(x=\"value\", y=\"model\", hue=\"metric\", data=dfScoreResults[(dfScoreResults[\"model\"].isin(bestModels))&(dfScoreResults[\"set\"]==\"test\")&(dfScoreResults[\"metric\"]!=\"MaxError\")])\n",
        "ax.set(title='Internal validation best models')\n",
        "plt.plot()\n",
        "plt.savefig('result_R2_RF-Vs-BestLGBM2.png', dpi=300, format='png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zi5XzpVNpz-P"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.set(rc = {'figure.figsize':(8,4)})\n",
        "f, (ax1, ax2) = plt.subplots(ncols=2, nrows=1, sharey=True)\n",
        "ax = sns.boxplot(x=\"value\", y=\"model\", hue=\"metric\", data=dfScoreResults[(dfScoreResults[\"model\"].isin([\"RF_model_3\",\"LGBM_model_17\"]))&(dfScoreResults[\"set\"]==\"test\")&(dfScoreResults[\"metric\"]!=\"MaxError\")],ax=ax1)\n",
        "ax = sns.boxplot(x=\"value\", y=\"model\", hue=\"metric\", data=dfScoreResults[(dfScoreResults[\"model\"].isin([\"RF_model_3\",\"LGBM_model_17\"]))&(dfScoreResults[\"set\"]==\"test\")&(dfScoreResults[\"metric\"]==\"MaxError\")],ax=ax2)\n",
        "f.suptitle('Internal validation best model')\n",
        "ax2.set_ylabel(\"\")\n",
        "plt.subplots_adjust(wspace=.01, hspace=0)\n",
        "plt.plot()\n",
        "plt.savefig('result_R2_RF-Vs-BestLGBM3.png', dpi=300, format='png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukLZd9yI3CfL"
      },
      "source": [
        "### **External validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xrKGYqKo2Q8Q"
      },
      "outputs": [],
      "source": [
        "ModelResultsTable.to_csv('MAO-B_Results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmGEIadQIKIh"
      },
      "outputs": [],
      "source": [
        "ModelResultsTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dHSi_v_PT_SS"
      },
      "outputs": [],
      "source": [
        "resultsTable = ModelResultsTable.drop([\"Params\"],axis=1)\n",
        "resultsTable = resultsTable.set_index('Model')\n",
        "sns.set(rc = {'figure.figsize':(8,4)})\n",
        "ax = sns.heatmap(resultsTable, annot=True, fmt='.3g',linewidths=.5, cmap=\"seismic\",vmin=.50,vmax=.95)\n",
        "ax.set(title='External validation best models')\n",
        "plt.savefig('result_RF-Vs-BestLGBM2.png', dpi=300, format='png', bbox_inches='tight', \n",
        "           dpi=300, format='png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fr0AEZ1gYPI"
      },
      "source": [
        "## **Conclusions**\n",
        "The LightGBM is slowly finding its way into practical use and may replace the RF as the most popular classifier. Our study shows that the emerging LightGBM also has potential in QSAR model and can deliver equally good results as the popular Random Forest. Both methods delivered comparable scores, in the internal and external validation, predicting the MAO-B inhibitors of small molecules.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-rK8l0wWnKK"
      },
      "source": [
        "### **Zip files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GW1ZSsfJWqbM"
      },
      "outputs": [],
      "source": [
        "! zip -r mao-b_results.zip . -i *.csv *.png"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MAO-B_Regressor.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}